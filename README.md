# âœï¸ Handwritten Digits Identification (C / C++)

**Course:** Programming Workshop in C & C++  
**Institution:** The Hebrew University of Jerusalem  
**Assignment #4 â€“ Neural Network Implementation**

---

## ğŸ¯ Overview
This assignment implements a **feed-forward neural network** for recognizing **handwritten digits (0â€“9)** from grayscale images.  
It was designed for students in the **Programming in C/C++ workshop**, combining object-oriented programming, operator overloading, and numerical computing.  
Although simplified, the model achieves about **96% accuracy** when using the provided pre-trained weights and biases.

---

## ğŸ§© Concept
The exercise introduces students to:
- The **basics of C++ classes**, constructors, destructors, and operator overloading.  
- The **Rule of Three**, **references**, and **exception handling**.  
- Building a **matrix math library** from scratch (no STL allowed).  
- Implementing a **4-layer neural network** manually using matrices and activation functions.

---

## ğŸ§  Theoretical Background
A **fully-connected feed-forward neural network** processes an input vector x through successive layers:

\[ y = f(Wx + b) \]

where:
- W: weight matrix  
- b: bias vector  
- f: activation function  

The networkâ€™s final output is a **probability distribution** over digits 0â€“9, produced by a **Softmax** layer.

---

## âš™ï¸ Network Architecture

| Layer | Type | Activation | Dimensions (Weights Ã— Bias) |
|:------|:------|:------------|:-----------------------------|
| 1 | Dense (Input â†’ Hidden) | ReLU | 784 Ã— 128, bias 128 |
| 2 | Dense (Hidden) | ReLU | 128 Ã— 64, bias 64 |
| 3 | Dense (Hidden) | ReLU | 64 Ã— 20, bias 20 |
| 4 | Dense (Output) | Softmax | 20 Ã— 10, bias 10 |

Pipeline:
```
r1 = ReLU(W1Â·x + b1)
r2 = ReLU(W2Â·r1 + b2)
r3 = ReLU(W3Â·r2 + b3)
r4 = Softmax(W4Â·r3 + b4)
```

Each image is a **28Ã—28 grayscale matrix** (values in [0,1]), flattened to a vector of size 784.  
The output is a probability vector of length 10, where the **index of the maximum value** corresponds to the predicted digit.

---

## ğŸ§® Activation Functions
Implemented manually in `Activation.cpp`:

- **ReLU(x)** = max(0, x)  
  Applies element-wise, ensuring non-linearity.  

- **Softmax(xáµ¢)** = eË£â± / Î£â‚– eË£áµ  
  Converts raw outputs into a normalized probability distribution.

---

## ğŸ§° Classes Implemented
All classes were coded **from scratch**, with no use of STL containers like `std::vector`.

| Class | Purpose | Highlights |
|:------|:---------|:-----------|
| `Matrix` | Handles all matrix operations | Operator overloading (`+`, `*`, `()`, `[]`, `<<`, `>>`), transpose, vectorize, dot, norm |
| `Activation` | Static functions for ReLU and Softmax | Uses function pointers for flexibility |
| `Dense` | Represents a single neural network layer | Holds weights, bias, and activation; applies layer computation |
| `MlpNetwork` | Combines all four layers into the full model | Executes inference and returns the predicted digit |

---

## ğŸ’¾ Input and Output

### **Input**
The program receives **8 binary files** containing the pre-trained weights and biases:
```
w1 w2 w3 w4 b1 b2 b3 b4
```

Then it waits for **user input** â€” a path to a binary image file.  
The image is read, flattened into a matrix, and fed into the network.

### **Output**
- Prints the **predicted digit** and the **confidence level** (probability).  
- Continues until user types `q`, which exits with code `0`.

Example:
```
$ ./mlpnetwork w1 w2 w3 w4 b1 b2 b3 b4
Please enter image path: images/img_42.bin
Network output: 7 (confidence 0.90)
Please enter image path: q
```

---

## ğŸ§± File Structure
```
â”œâ”€â”€ Matrix.h / Matrix.cpp           # Matrix implementation
â”œâ”€â”€ Activation.h / Activation.cpp   # ReLU & Softmax
â”œâ”€â”€ Dense.h / Dense.cpp             # Neural network layer
â”œâ”€â”€ MlpNetwork.h / MlpNetwork.cpp   # 4-layer neural network
â”œâ”€â”€ main.cpp                        # Loads weights, runs inference
â”œâ”€â”€ Makefile                        # Compilation configuration
â”œâ”€â”€ plot_img.py                     # Utility for displaying images
â””â”€â”€ Ex4.pdf                         # Full exercise description (this document)
```

---

## âš™ï¸ Compilation and Execution

### 1ï¸âƒ£ Build
Compile the program using the provided Makefile:
```bash
make mlpnetwork
```

### 2ï¸âƒ£ Run
Run the executable with all weight and bias file paths:
```bash
./mlpnetwork w1 w2 w3 w4 b1 b2 b3 b4
```

Then input the path to a digit image file (binary format).

### 3ï¸âƒ£ Exit
Type `q` to quit the program.  
Return code `0` indicates successful termination.

---

## ğŸ§¨ Error Handling
Exception handling uses standard C++ exceptions:

| Error Type | Exception | Description |
|-------------|------------|-------------|
| Invalid matrix size | `std::length_error` | Mismatched dimensions |
| Out of range access | `std::out_of_range` | Index out of range |
| Invalid user input | `std::runtime_error` | Bad input file |
| Memory allocation failure | `std::bad_alloc` | Raised automatically |

---

## ğŸ§ª Testing and Validation
- Students were encouraged to test their code using **Valgrind** to ensure **no memory leaks**.  
- Code had to compile and run **without warnings or STL usage**.  
- Expected network accuracy â‰ˆ **96%**, small deviations allowed due to floating-point arithmetic.

---

## ğŸ“š Learning Objectives
- Implementing OOP and polymorphism in C++.  
- Practicing **operator overloading** and **exception handling**.  
- Understanding the structure of a simple **feed-forward neural network**.  
- Writing modular, reusable, and readable C++ code without STL.

---

## ğŸ§‘â€ğŸ« Author & Instruction Context
This project was developed and supervised by **Assaf Gozlan** as part of his teaching duties  
in the *C / C++ Programming Workshop* course at **The Hebrew University of Jerusalem**.  
The exercise was distributed to students in May 2022 and served as an introduction to  
practical neural network implementation in native C++.

---

Â© 2022 â€” Hebrew University of Jerusalem, Department of Computer Science
